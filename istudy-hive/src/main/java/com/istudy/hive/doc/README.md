## 数据分层
    数据仓库的数据分层通常分为集市层、中间层、基础数据层上下三层结构
    
![Alt text](../doc/落地数仓分层.jpg)

    按照以上分层方式，开发重心就在DWD层，就是明细数据层，这里主要是一些宽表，存储的还是明细数据；
    DWS层，会针对不同的维度，对数据进行聚合了。DWS层算是集市层，这里一般按照主题进行划分，属于维度建模的范畴；
    ADS就是偏应用层，各种报表的输出。
    DIM层是数据仓库数据中，各层公用的维度数据。比如：省市县数据。
    
## 数据集市和数据仓库的主要区别
    数据仓库是企业级的，能为整个企业各个部门的运行提供决策支持手段；
    
    数据集市则是一种微型的数据仓库,它通常有更少的数据,更少的主题区域,
    以及更少的历史数据,因此是部门级的，一般只能为某个局部范围内的管理人员服务，因此也称之为部门级数据仓库。
    
## 数据倾斜概念
    由于数据分配不均匀，造成数据大量集中到一点，造成数据热点。
    数据倾斜主要表现在，map/reduce程序执行时，reduce节点大部分执行完毕，
    但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长，
    这是因为某一个key的条数比其他key多很多(有时是百倍或者千倍之多)，
    这条Key所在的reduce节点所处理的数据量比其他节点就大很多，从而导致某几个节点迟迟运行不完。
    
## 怎么判断数据有没有倾斜？
    1、分析节点资源管理器，如果大部分节点已经执行完成，而个别节点长时间执行不完，很可能发生了数据倾斜；
    2、分析执行日志，作业在reduce阶段停留在99%，很长时间完成不了，很可能发生了数据倾斜；
    
## 容易造成数据倾斜的原因
    基本业务逻辑是造成数据倾斜的主要原因：
    1、group by逻辑造成
    2、distinct count(distinct xx)
    3、小表join大表
    4、大表join大表
    
## 解决方案
    1、调优参数
    set hive.map.aggr=true；
    开启map端聚合，效率更高但需要更多的内存
    
    set hive.groupby.skewindata=true;
    开启group by数据倾斜时负载均衡，生成的查询计划会有两个MRJob。
    
    第一个MRJob中，Map的输出结果集合会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的GroupBy Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；
    
    第二个MRJob再根据预处理的数据结果按照GroupBy Key分布到Reduce中（这个过程可以保证相同的GroupBy Key被分布到同一个Reduce中），最后完成最终的聚合操作。
      
> hive数据倾斜
>> 一般发生在SQL中，group by和join on上，并且和数据逻辑绑定比较深。

> spark中数据倾斜：包括spark streaming和spark SQL，主要表现：
>> 1)executor lost,OOM.shuffle过程出错
>> 2)Driver OOM
>> 3)单个executor执行时间特别久，整个任务卡在某个阶段不能结束
>> 4)正常运行的任务突然失败

> 常见的数据倾斜原因：
>> 1)key分布不均匀
>> 2)建表时考虑不周
>> 3)业务数据激增
>> 4)某些HQL语句本身就存在数据倾斜

## 数据仓库最显著的特点
    ETL - 它自己不产生数据，所以需要ETL操作；
    历史性 - 存储一切可追溯的历史信息；
    分析性 - 分析能力强。





