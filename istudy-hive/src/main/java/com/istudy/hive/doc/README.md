## 数据分层
    数据仓库的数据分层通常分为集市层、中间层、基础数据层上下三层结构

## 数仓建模流程
    业务模型->领域/概念模型->逻辑模型->物理模型

    业务建模: 生成业务模型，主要解决业务层面的分解和程序化。
    领域建模: 生成领域模型，主要是对业务模型进行抽象处理，生成领域概念模型。
    逻辑建模: 生成逻辑模型，主要是将领域模型的概念实体以及实体之间的关系进行数据库层次的逻辑化。
    物理建模: 生成物理模型，主要解决，逻辑模型针对不同关系型数据库的物理化以及性能等一些具体的技术问题。
    
![Alt text](../doc/落地数仓分层.jpg)

    按照以上分层方式，开发重心就在DWD层，就是明细数据层，这里主要是一些宽表，存储的还是明细数据；
    DWS层，会针对不同的维度，对数据进行聚合了。DWS层算是集市层，这里一般按照主题进行划分，属于维度建模的范畴；
    ADS就是偏应用层，各种报表的输出。
    DIM层是数据仓库数据中，各层公用的维度数据。比如：省市县数据。
    
## 数据集市和数据仓库的主要区别
    数据仓库是企业级的，能为整个企业各个部门的运行提供决策支持手段；
    
    数据集市则是一种微型的数据仓库,它通常有更少的数据,更少的主题区域,
    以及更少的历史数据,因此是部门级的，一般只能为某个局部范围内的管理人员服务，因此也称之为部门级数据仓库。
    
## 数据倾斜概念
    由于数据分配不均匀，造成数据大量集中到一点，造成数据热点。
    数据倾斜主要表现在，map/reduce程序执行时，reduce节点大部分执行完毕，
    但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长，
    这是因为某一个key的条数比其他key多很多(有时是百倍或者千倍之多)，
    这条Key所在的reduce节点所处理的数据量比其他节点就大很多，从而导致某几个节点迟迟运行不完。
    
## 怎么判断数据有没有倾斜？
    1、分析节点资源管理器，如果大部分节点已经执行完成，而个别节点长时间执行不完，很可能发生了数据倾斜；
    2、分析执行日志，作业在reduce阶段停留在99%，很长时间完成不了，很可能发生了数据倾斜；
    
## 容易造成数据倾斜的原因
    基本业务逻辑是造成数据倾斜的主要原因：
    1、group by逻辑造成
    2、distinct count(distinct xx)
    3、小表join大表
    4、大表join大表
    
## 解决方案
    1、调优参数
    set hive.map.aggr=true；
    开启map端聚合，效率更高但需要更多的内存
    
    set hive.groupby.skewindata=true;
    开启group by数据倾斜时负载均衡，生成的查询计划会有两个MRJob。
    
    第一个MRJob中，Map的输出结果集合会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的GroupBy Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；
    
    第二个MRJob再根据预处理的数据结果按照GroupBy Key分布到Reduce中（这个过程可以保证相同的GroupBy Key被分布到同一个Reduce中），最后完成最终的聚合操作。
      
> hive数据倾斜
>> 一般发生在SQL中，group by和join on上，并且和数据逻辑绑定比较深。

> spark中数据倾斜：包括spark streaming和spark SQL，主要表现：
>> 1)executor lost,OOM.shuffle过程出错
>> 2)Driver OOM
>> 3)单个executor执行时间特别久，整个任务卡在某个阶段不能结束
>> 4)正常运行的任务突然失败

> 常见的数据倾斜原因：
>> 1)key分布不均匀
>> 2)建表时考虑不周
>> 3)业务数据激增
>> 4)某些HQL语句本身就存在数据倾斜

## 数据仓库最显著的特点
    ETL - 它自己不产生数据，所以需要ETL操作；
    历史性 - 存储一切可追溯的历史信息；
    分析性 - 分析能力强。

### Hive整体架构
    Hive是底层封装了Hadoop的数据仓库处理工具，它运行在Hadoop基础上
![Alt text](../doc/Hive整体架构.jpg)

    Hive中的元数据通常包含表名、列、分区及其相关属性，表数据所在目录的位置信息，Metastore默认存在自带的Derby数据库中。
    由于Derby数据库不适合多用户操作，并且数据存储目录不固定，不方便管理，因此，通常都将元数据存储在MySQL数据库。

### 结构化、半结构化和非结构化数据
    结构化数据:指关系模型数据，即以关系数据库表形式管理的数据，结合到典型场景中更容易理解，比如企业ERP、OA、HR里的数据。
    非结构化数据:指数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表现的数据。如word、pdf、ppt及各种格式的图片、视频等。
    半结构化数据:指非关系模型的、有基本固定结构模式的数据，例如日志文件、XML文档、JSON文档、E-mail等

### 理解数据仓库中星型模型和雪花模型
    星型模型是一种多维的数据关系，它由一个事实表和一组维表组成。每个维表都有一个维作为主键，所有这些维的主键组合成事实表的主键。
    强调的是对维度进行预处理，将多个维度集合到一个事实表，形成一个宽表。这也是我们在使用hive时，经常会看到一些大宽表的原因，
    大宽表一般都是事实表，包含了维度关联的主键和一些度量信息，而维度表则是事实表里面维度的具体信息，使用时候一般通过join来组合数据，
    相对来说对OLAP的分析比较方便。
![Alt text](../doc/星型模型.jpg)

    当有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上时，其图解就像多个雪花连接在一起，故称雪花模型。
    雪花模型是对星型模型的扩展。它对星型模型的维表进一步层次化，原有的各维表可能被扩展为小的事实表，形成一些局部的 "层次 " 区域，
    这些被分解的表都连接到主维度表而不是事实表。雪花模型更加符合数据库范式，减少数据冗余，但是在分析数据的时候，操作比较复杂，
    需要join的表比较多所以其性能并不一定比星型模型高。
![Alt text](../doc/雪花模型.jpg)

    星型模型和雪花模型的优劣对比
![Alt text](../doc/两则比对.jpg)

    应用场景
    星型模型的设计方式主要带来的好处是能够提升查询效率，因为生成的事实表已经经过预处理，主要的数据都在事实表里面，所以只要扫描实时表就能够进行大量的查询，而不必进行大量的join，其次维表数据一般比较少，在join可直接放入内存进行join以提升效率，除此之外，星型模型的事实表可读性比较好，不用关联多个表就能获取大部分核心信息，设计维护相对比较简答。
    星型模型的设计方式是比较符合数据库范式的理念，设计方式比较正规，数据冗余少，但在查询的时候可能需要join多张表从而导致查询效率下降，此外规范化操作在后期维护比较复杂。

    总结
    通过上面的对比，我们可以发现数据仓库大多数时候是比较适合使用星型模型构建底层数据Hive表，通过大量的冗余来提升查询效率，星型模型对OLAP的分析引擎支持比较友好，这一点在Kylin中比较能体现。而雪花模型在关系型数据库中如MySQL，Oracle中非常常见，尤其像电商的数据库表。在数据仓库中雪花模型的应用场景比较少，但也不是没有，所以在具体设计的时候，可以考虑是不是能结合两者的优点参与设计，以此达到设计的最优化目的。

### 数据治理相关
#### 资产治理平台
元数据采集
数据标准管理
数据质量监控
敏感数据保护
资源成本治理

### 指标体系
#### 经销商实力指标
资金规模
客户资源
网点数量
经营竞品
#### 经销商贡献指标
销售金额
单店贡献
库销比
费效比
串货及违规

### 数据标签化
人
消费者数据打通-偏好类标签,预测类标签
货
人货场数据联动-口味类型标签,交易标签
场
人货关系数据打通-地理标签,特征标签
其他
人货场标签融合-兴趣标签,人群标签

### 大数据治理的需求
    数据质量：确保数据准确、一致、完整。
    元数据管理：提供数据目录和血缘追踪。
    安全性与合规：保护隐私，满足法规。
    可扩展性：支持 PB 级数据和亿级并发。

元数据Metadata-描述数据特征的数据，是数据治理的基础，可分析数据来龙去脉，提供血缘关系、影响分析及数据地图等。
数据标准Data Standard-对数据进行统一约束和规范，评估标准落地情况，提供系统建设依据。
数据质量Data Quality-发现质量问题，提供绩效评分，出具质量分析报告，发起数据整改。让数据清澈如水。
主数据Main Data-对需要共享的数据建立统一视图和集中管理，为各业务系统数据调用提供黄金数据。
数据资产Data Assets-将数据作为资产，对外提供数据服务，进行不同角色的目录化管理，获知资产访问方式、利用情况等。
数据生命周期Data Life Cycle-对数据进行自动归档、销毁和全生命周期监控。
数据安全Data Security-贯穿于数据治理全过程，保证数据的安全。提供对隐私数据的加密、脱敏、模糊化处理、及对数据库授权监控。

### 开源元数据平台DataHub-可替换atlas
DataHub有巨大的生态系统，预构建集成包括Kafka, Airflow, MySQL, SQL Server, Postgres, LDAP, Snowflake, Hive, BigQuery等等；且社区正在不断添加更多的集成。

元数据应用
元数据管理一般具备如下功能：

**搜索和发现：**数据表、字段、标签、使用信息
**访问控制：**访问控制组、用户、策略
**数据血缘：**管道执行、查询
**合规性：**数据隐私/合规性注释类型的分类
**数据管理：**数据源配置、摄取配置、保留配置、数据清除策略
**AI 可解释性、再现性：**特征定义、模型定义、训练运行执行、问题陈述
**数据操作：**管道执行、处理的数据分区、数据统计
**数据质量：**数据质量规则定义、规则执行结果、数据统计

### Apache Atlas 如何记录数据血缘
Hive 数据血缘：当你使用 Hive 执行查询时，Atlas 能够记录查询的表、字段等信息，并推断出查询操作之间的血缘关系。例如，创建一个新的 Hive 表时，Atlas 可以记录该表是从哪些源表中抽取的。
Spark 数据血缘：当使用 Apache Spark 执行数据处理时，Atlas 可以记录 Spark 作业的输入和输出数据，并追踪 Spark 中的转换操作。例如，Atlas 可以记录某个 Spark 作业从 HDFS 中读取数据，经过处理后存入一个新的 Hive 表。
ETL 工具：如果企业使用专门的 ETL 工具（如 Apache Nifi、Talend 等），这些工具也可以通过 API 集成到 Atlas，记录数据的流转过程和变换操作。

Atlas支持Hadoop、Spark等大数据平台
Atlas中配置需要进行数据血缘分析和追踪的数据源，例如HDFS、Hive、Kafka等

### atlas如何做数据质量-可参考datavines
Atlas支持从多种数据源（如数据库、Hadoop集群）自动收集数据，并实时计算预定义指标的度量值‌。

### Atlas依赖组件
Kafka,Hbase,Solr



